{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from google.datalab.ml import TensorBoard\n",
    "print(tf.__version__)\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = 'embedding_experiment'\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = pd.read_pickle(\"./data/movies.pkl\")\n",
    "df_rating = pd.read_pickle(\"./data/rating.pkl\")\n",
    "df_tags = pd.read_pickle(\"./data/tags.pkl\")\n",
    "df_links = pd.read_pickle(\"./data/links.pkl\")\n",
    "df_genome_scores = pd.read_pickle(\"./data/genome-scores.pkl\")\n",
    "df_genome_tags = pd.read_pickle(\"./data/genome-tags.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic test & training set construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movieId', 'userId', 'movieId_rating', 'rating', 'timestamp',\n",
       "       'movieId_movies', 'title', 'genres', 'movie_year', '(no genres listed)',\n",
       "       'Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime',\n",
       "       'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'IMAX',\n",
       "       'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War',\n",
       "       'Western'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset = df_rating.join(df_movies, on=['movieId'], lsuffix='_rating', rsuffix='_movies',how='inner')\n",
    "df_dataset = df_dataset.reset_index(drop=True)\n",
    "df_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test length: 3548125 , Training length: 14177840\n"
     ]
    }
   ],
   "source": [
    "msk = np.random.rand(len(df_dataset)) < 0.8\n",
    "df_train = df_dataset[msk]\n",
    "df_test = df_dataset[~msk]\n",
    "\n",
    "print(\"Test length: %s , Training length: %s\" % (len(df_test),len(df_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = list(df_dataset.columns)\n",
    "FEATURES.remove('movieId_rating')\n",
    "FEATURES.remove('timestamp')\n",
    "FEATURES.remove('movieId_movies')\n",
    "FEATURES.remove('(no genres listed)')\n",
    "FEATURES.remove('title') ## for now, no textual features without tokenizers\n",
    "FEATURES.remove('genres')\n",
    "LABEL = FEATURES.pop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['movieId', 'rating', 'movie_year', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'IMAX', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'] \n",
      "\n",
      "Label: userId \n",
      "\n",
      "Feature Col types: movieId          int64\n",
      "rating         float64\n",
      "movie_year     float64\n",
      "Action           int64\n",
      "Adventure        int64\n",
      "Animation        int64\n",
      "Children         int64\n",
      "Comedy           int64\n",
      "Crime            int64\n",
      "Documentary      int64\n",
      "Drama            int64\n",
      "Fantasy          int64\n",
      "Film-Noir        int64\n",
      "Horror           int64\n",
      "IMAX             int64\n",
      "Musical          int64\n",
      "Mystery          int64\n",
      "Romance          int64\n",
      "Sci-Fi           int64\n",
      "Thriller         int64\n",
      "War              int64\n",
      "Western          int64\n",
      "dtype: object \n",
      "\n",
      "Label Col types: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Features: %s \\r\\n\" % (FEATURES))\n",
    "print(\"Label: %s \\r\\n\" % (LABEL))\n",
    "print(\"Feature Col types: %s \\r\\n\" % df_train[FEATURES].dtypes)\n",
    "print(\"Label Col types: %s \\r\\n\" % df_train[LABEL].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_input_fn(df, num_epochs):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = df[FEATURES],\n",
    "    y = df[LABEL],\n",
    "    batch_size = 128,\n",
    "    num_epochs = num_epochs,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 1000\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_eval_input_fn(df):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = df[FEATURES],\n",
    "    y = df[LABEL],\n",
    "    batch_size = 128,\n",
    "    shuffle = False,\n",
    "    queue_capacity = 1000\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn(df):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = df[FEATURES],\n",
    "    y = None,\n",
    "    batch_size = 128,\n",
    "    shuffle = False,\n",
    "    queue_capacity = 1000\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_cols():\n",
    "  input_columns = []\n",
    "  ## input_columns = [tf.feature_column.numeric_column(k) for k in FEATURES] -- No fields are fully numerical\n",
    "  \n",
    "  ## The binary fields:\n",
    "  binary_fields = ['Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', \n",
    "                   'IMAX', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'] \n",
    "  \n",
    "  binary_columns = [tf.feature_column.categorical_column_with_identity(k, num_buckets=2,default_value=0) for k in binary_fields]\n",
    "\n",
    "  ## Embedding the category fields\n",
    "  #input_columns = tf.feature_column.embedding_column(categorical_column=binary_columns,dimension=10)\n",
    "  \n",
    "  input_columns = [tf.feature_column.embedding_column(tf.feature_column.crossed_column(binary_columns,20**2),dimension=5)]\n",
    "  \n",
    "  return input_columns #binary_columns #input_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[_EmbeddingColumn(categorical_column=_CrossedColumn(keys=(_IdentityCategoricalColumn(key='Action', num_buckets=2, default_value=0), _IdentityCategoricalColumn(key='Adventure', num_buckets=2, default_value=0), _IdentityCategoricalColumn(key='Animation', num_buckets=2, default_value=0), _IdentityCategoricalColumn(key='Children', num_buckets=2, default_value=0), _IdentityCategoricalColumn(key='Comedy', num_buckets=2, default_value=0), _IdentityCategoricalColumn(key='Crime', num_buckets=2, default_value=0), _IdentityCategoricalColumn(key='Documentary', num_buckets=2, default_value=0), _IdentityCategoricalColumn(key='Drama', num_buckets=2, default_value=0), _IdentityCategoricalColumn(key='Fantasy', num_buckets=2, default_value=0), _IdentityCategoricalColumn(key='Film-Noir', num_buckets=2, default_value=0), _IdentityCategoricalColumn(key='Horror', num_buckets=2, default_value=0), _IdentityCategoricalColumn(key='IMAX', num_buckets=2, default_value=0), _IdentityCategoricalColumn(key='Musical', num_buckets=2, default_value=0), _IdentityCategoricalColumn(key='Mystery', num_buckets=2, default_value=0), _IdentityCategoricalColumn(key='Romance', num_buckets=2, default_value=0), _IdentityCategoricalColumn(key='Sci-Fi', num_buckets=2, default_value=0), _IdentityCategoricalColumn(key='Thriller', num_buckets=2, default_value=0), _IdentityCategoricalColumn(key='War', num_buckets=2, default_value=0), _IdentityCategoricalColumn(key='Western', num_buckets=2, default_value=0)), hash_bucket_size=160000, hash_key=None), dimension=5, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x7f7d75c05748>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True)]\n"
     ]
    }
   ],
   "source": [
    "print(make_feature_cols())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model train & evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(output_dir, num_train_steps):\n",
    "  \n",
    "    EVAL_INTERVAL = 300\n",
    "    run_config = tf.estimator.RunConfig(save_checkpoints_secs = EVAL_INTERVAL,\n",
    "                                      keep_checkpoint_max = 3)\n",
    "    #estimator = tf.estimator.LinearRegressor(\n",
    "    #                   model_dir = output_dir,\n",
    "    #                   feature_columns = make_feature_cols())\n",
    "    \n",
    "    estimator = tf.estimator.DNNRegressor(\n",
    "                       model_dir = output_dir,\n",
    "                       feature_columns = make_feature_cols(),\n",
    "                       hidden_units = [64, 32,16,8],\n",
    "                       config = run_config)\n",
    "    \n",
    "    train_spec=tf.estimator.TrainSpec(\n",
    "                       input_fn = make_train_input_fn(df_train, num_epochs = 10),\n",
    "                       max_steps = num_train_steps)\n",
    "\n",
    "    #exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "\n",
    "    eval_spec=tf.estimator.EvalSpec(\n",
    "                       input_fn = make_eval_input_fn(df_test),\n",
    "                       steps = None,\n",
    "                       start_delay_secs = 1, # start evaluating after N seconds\n",
    "                       throttle_secs = EVAL_INTERVAL,  # evaluate every N seconds\n",
    "                       #exporters = exporter\n",
    "    )\n",
    "    \n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_master': '', '_keep_checkpoint_max': 3, '_evaluation_master': '', '_session_config': None, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None, '_task_id': 0, '_num_ps_replicas': 0, '_save_summary_steps': 100, '_train_distribute': None, '_tf_random_seed': None, '_service': None, '_num_worker_replicas': 1, '_model_dir': 'embedding_experiment', '_log_step_count_steps': 100, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7d75b937f0>, '_global_id_in_cluster': 0, '_save_checkpoints_secs': 300}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 300 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into embedding_experiment/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 2332946300000.0\n",
      "INFO:tensorflow:global_step/sec: 92.4032\n",
      "INFO:tensorflow:step = 101, loss = 53730460000.0 (1.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.036\n",
      "INFO:tensorflow:step = 201, loss = 399484600000.0 (0.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.372\n",
      "INFO:tensorflow:step = 301, loss = 22428836000.0 (0.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.212\n",
      "INFO:tensorflow:step = 401, loss = 134122020000.0 (0.786 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.102\n",
      "INFO:tensorflow:step = 501, loss = 466428360000.0 (0.806 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.526\n",
      "INFO:tensorflow:step = 601, loss = 1694716400.0 (0.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.097\n",
      "INFO:tensorflow:step = 701, loss = 1577405300.0 (0.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.145\n",
      "INFO:tensorflow:step = 801, loss = 1053408100.0 (0.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.425\n",
      "INFO:tensorflow:step = 901, loss = 40478670000.0 (0.816 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into embedding_experiment/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 121582340000.0.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-13-15:06:11\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from embedding_experiment/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-13-15:08:58\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 2866427000.0, global_step = 1000, loss = 366899000000.0\n"
     ]
    }
   ],
   "source": [
    "# Run training    \n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "train_and_evaluate(OUTDIR, num_train_steps = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rmse(model, df):\n",
    "  metrics = model.evaluate(input_fn = make_eval_input_fn(df))\n",
    "  print('RMSE on dataset = {}'.format(np.sqrt(metrics['average_loss'])))\n",
    "#print_rmse(model, df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorflowBoard for debugging purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>TensorBoard was started successfully with pid 912900. Click <a href=\"/_proxy/58461/\" target=\"_blank\">here</a> to access it.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "912900"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorBoard().start(OUTDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shutting down TensorflowBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to list Tensorboard instances\n",
    "TensorBoard().list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped TensorBoard with pid 783168\n",
      "Stopped TensorBoard with pid 905119\n"
     ]
    }
   ],
   "source": [
    "pids_df = TensorBoard.list()\n",
    "if not pids_df.empty:\n",
    "    for pid in pids_df['pid']:\n",
    "        TensorBoard().stop(pid)\n",
    "        print('Stopped TensorBoard with pid {}'.format(pid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
